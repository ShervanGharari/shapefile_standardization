{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from shapely.ops import unary_union\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import Point\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import requests\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def shp_hill (name_of_source_file, name_of_cat_file, name_of_result_file, epsilon):\n",
    "    \"\"\"\n",
    "    @ author:                  Shervan Gharari\n",
    "    @ Github:                  https://github.com/ShervanGharari/shapefile_standardization\n",
    "    @ author's email id:       sh.gharari@gmail.com\n",
    "    @license:                  MIT\n",
    "\n",
    "    This function gets name of a shapefile and remove inernal holes\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    name_of_source_file: string, the name of the source file including path and extension\n",
    "    name_of_cat_file: string, the name of the corresponding catchment (subbasin)\n",
    "        for the unresolved hills\n",
    "    name_of_result_file: string, the name of the file that includes fixed shapes\n",
    "        including path and extension\n",
    "    epsilon\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    Saves Files\n",
    "    -------\n",
    "    a shp file that includes corrected polygones\n",
    "    a possible shapefile that includes the fixed shapes\n",
    "    \"\"\"\n",
    "    \n",
    "    shp = gpd.read_file(name_of_source_file)\n",
    "    cat = gpd.read_file(name_of_cat_file)\n",
    "    shp_all = None\n",
    "\n",
    "    ## STEP1, load a shapefile, and find its intesection with itself. there are\n",
    "    ## there should be some holes in the shapefile. the holes are given as a separaete shape\n",
    "    shp_temp = gpd.overlay(shp, shp, how='intersection')\n",
    "    shp_temp = shp_temp [shp_temp.FID_1 != shp_temp.FID_2]\n",
    "    shp_temp = shp_temp.reset_index()    \n",
    "    shp_temp = gpd.overlay(shp, shp_temp, how='difference')\n",
    "    shp_temp = shp_temp.reset_index()\n",
    "    \n",
    "    ## STEP2, remove possible cat from the unresolved costal hillslope\n",
    "    shp_temp = gpd.overlay(shp_temp, cat, how='difference')\n",
    "    shp_temp = shp_temp.reset_index()\n",
    "    \n",
    "    ## STEP3, break the touching polygons into separate polygons, remove the links (lines)\n",
    "    # shp_temp = shp_temp.buffer(-epsilon).buffer(epsilon)\n",
    "    shp_temp = shp_temp.buffer(-epsilon, cap_style=2, join_style=2)\n",
    "    shp_temp = gpd.GeoDataFrame(shp_temp)\n",
    "    shp_temp.columns = ['geometry'] # rename the colomn to geometry\n",
    "    shp_temp.to_file('temp4.shp')\n",
    "\n",
    "    ## STEP4, break the polygones into separete shape in a shapefile\n",
    "    shp = gpd.read_file('temp4.shp')\n",
    "    for index, _ in shp.iterrows():\n",
    "        polys = shp.geometry.iloc[index] # get the shape\n",
    "        if polys is not None:\n",
    "            if polys.type == 'Polygon':\n",
    "                shp_temp = gpd.GeoSeries(polys) # convert multipolygon to a shapefile with polygons only\n",
    "                shp_temp = gpd.GeoDataFrame(shp_temp) # convert multipolygon to a shapefile with polygons\n",
    "                shp_temp.columns = ['geometry'] # naming geometry column\n",
    "            if polys.type == 'MultiPolygon':\n",
    "                shp_temp = gpd.GeoDataFrame(polys) # convert multipolygon to a shapefile with polygons \n",
    "                shp_temp.columns = ['geometry'] # naming geometry column\n",
    "            if shp_all is None:\n",
    "                shp_all = shp_temp\n",
    "            else:\n",
    "                shp_all = shp_all.append(shp_temp)\n",
    "    shp_all = shp_all.buffer(epsilon, cap_style=2, join_style=2)\n",
    "    shp_all.to_file(name_of_result_file)\n",
    "    shp_all = gpd.read_file(name_of_result_file)\n",
    "    # add COMIDS\n",
    "    shp_all['COMID'] = np.arange(shp_all.shape[0])+max(cat.COMID)+1\n",
    "    shp_all = shp_all.set_crs(\"EPSG:4326\")\n",
    "    shp_all = shp_all.drop(columns=['FID'])\n",
    "    shp_all.to_file(name_of_result_file)\n",
    "\n",
    "\n",
    "def intersection_shp(shp_1, shp_2):\n",
    "    \"\"\"\n",
    "    @ author:                  Shervan Gharari\n",
    "    @ Github:                  https://github.com/ShervanGharari/candex\n",
    "    @ author's email id:       sh.gharari@gmail.com\n",
    "    @license:                  Apache2\n",
    "    This fucntion intersect two shapefile. It keeps the fiels from the first and second shapefiles (identified by S_1_ and \n",
    "    S_2_). It also creats other field including AS1 (area of the shape element from shapefile 1), IDS1 (an arbitary index\n",
    "    for the shapefile 1), AS2 (area of the shape element from shapefile 1), IDS2 (an arbitary index for the shapefile 1), \n",
    "    AINT (the area of teh intersected shapes), AP1 (the area of the intersected shape to the shapes from shapefile 1),\n",
    "    AP2 (the area of teh intersected shape to the shapefes from shapefile 2), AP1N (the area normalized in the case AP1\n",
    "    summation is not 1 for a given shape from shapefile 1, this will help to preseve mass if part of the shapefile are not \n",
    "    intersected), AP2N (the area normalized in the case AP2 summation is not 1 for a given shape from shapefile 2, this\n",
    "    will help to preseve mass if part of the shapefile are not intersected)\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    shp1: geo data frame, shapefile 1\n",
    "    shp2: geo data frame, shapefile 2\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result: a geo data frame that includes the intersected shapefile and area, percent and normalized percent of each shape\n",
    "    elements in another one\n",
    "    \"\"\"\n",
    "    # Calculating the area of every shapefile (both should be in degree or meters)\n",
    "    column_names = shp_1.columns\n",
    "    column_names = list(column_names)\n",
    "\n",
    "    # removing the geometry from the column names\n",
    "    column_names.remove('geometry')\n",
    "\n",
    "    # renaming the column with S_1\n",
    "    for i in range(len(column_names)):\n",
    "        shp_1 = shp_1.rename(\n",
    "            columns={column_names[i]: 'S_1_' + column_names[i]})\n",
    "\n",
    "    column_names = shp_2.columns\n",
    "    column_names = list(column_names)\n",
    "\n",
    "    # removing the geometry from the colomn names\n",
    "    column_names.remove('geometry')\n",
    "\n",
    "    # renaming the column with S_2\n",
    "    for i in range(len(column_names)):\n",
    "        shp_2 = shp_2.rename(\n",
    "            columns={column_names[i]: 'S_2_' + column_names[i]})\n",
    "\n",
    "    # Caclulating the area for shp1\n",
    "    shp_1['AS1'] = shp_1.area\n",
    "    shp_1['IDS1'] = np.arange(shp_1.shape[0])+1\n",
    "\n",
    "    # Caclulating the area for shp2\n",
    "    shp_2['AS2'] = shp_2.area\n",
    "    shp_2['IDS2'] = np.arange(shp_2.shape[0])+1\n",
    "\n",
    "    # making intesection\n",
    "    result = spatial_overlays (shp_1, shp_2, how='intersection')\n",
    "\n",
    "    # Caclulating the area for shp2\n",
    "    result['AINT'] = result['geometry'].area\n",
    "    result['AP1'] = result['AINT']/result['AS1']\n",
    "    result['AP2'] = result['AINT']/result['AS2']\n",
    "    \n",
    "    \n",
    "    # taking the part of data frame as the numpy to incread the spead\n",
    "    # finding the IDs from shapefile one\n",
    "    ID_S1 = np.array (result['IDS1'])\n",
    "    AP1 = np.array(result['AP1'])\n",
    "    AP1N = AP1 # creating the nnormalized percent area\n",
    "    ID_S1_unique = np.unique(ID_S1) #unique idea\n",
    "    for i in ID_S1_unique:\n",
    "        INDX = np.where(ID_S1==i) # getting the indeces\n",
    "        AP1N[INDX] = AP1[INDX] / AP1[INDX].sum() # normalizing for that sum\n",
    "        \n",
    "    # taking the part of data frame as the numpy to incread the spead\n",
    "    # finding the IDs from shapefile one\n",
    "    ID_S2 = np.array (result['IDS2'])\n",
    "    AP2 = np.array(result['AP2'])\n",
    "    AP2N = AP2 # creating the nnormalized percent area\n",
    "    ID_S2_unique = np.unique(ID_S2) #unique idea\n",
    "    for i in ID_S2_unique:\n",
    "        INDX = np.where(ID_S2==i) # getting the indeces\n",
    "        AP2N[INDX] = AP2[INDX] / AP2[INDX].sum() # normalizing for that sum\n",
    "        \n",
    "    result ['AP1N'] = AP1N\n",
    "    result ['AP2N'] = AP2N\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "def spatial_overlays(df1, df2, how='intersection', reproject=True):\n",
    "    \"\"\"Perform spatial overlay between two polygons.\n",
    "    Currently only supports data GeoDataFrames with polygons.\n",
    "    Implements several methods that are all effectively subsets of\n",
    "    the union.\n",
    "    \n",
    "    Omer Ozak\n",
    "    ozak\n",
    "    https://github.com/ozak\n",
    "    https://github.com/geopandas/geopandas/pull/338\n",
    "    Parameters\n",
    "    ----------\n",
    "    df1 : GeoDataFrame with MultiPolygon or Polygon geometry column\n",
    "    df2 : GeoDataFrame with MultiPolygon or Polygon geometry column\n",
    "    how : string\n",
    "        Method of spatial overlay: 'intersection', 'union',\n",
    "        'identity', 'symmetric_difference' or 'difference'.\n",
    "    use_sindex : boolean, default True\n",
    "        Use the spatial index to speed up operation if available.\n",
    "    Returns\n",
    "    -------\n",
    "    df : GeoDataFrame\n",
    "        GeoDataFrame with new set of polygons and attributes\n",
    "        resulting from the overlay\n",
    "    \"\"\"\n",
    "    df1 = df1.copy()\n",
    "    df2 = df2.copy()\n",
    "    df1['geometry'] = df1.geometry.buffer(0)\n",
    "    df2['geometry'] = df2.geometry.buffer(0)\n",
    "    if df1.crs!=df2.crs and reproject:\n",
    "        print('Data has different projections.')\n",
    "        print('Converted data to projection of first GeoPandas DatFrame')\n",
    "        df2.to_crs(crs=df1.crs, inplace=True)\n",
    "    if how=='intersection':\n",
    "        # Spatial Index to create intersections\n",
    "        spatial_index = df2.sindex\n",
    "        df1['bbox'] = df1.geometry.apply(lambda x: x.bounds)\n",
    "        df1['sidx']=df1.bbox.apply(lambda x:list(spatial_index.intersection(x)))\n",
    "        pairs = df1['sidx'].to_dict()\n",
    "        nei = []\n",
    "        for i,j in pairs.items():\n",
    "            for k in j:\n",
    "                nei.append([i,k])\n",
    "        pairs = gpd.GeoDataFrame(nei, columns=['idx1','idx2'], crs=df1.crs)\n",
    "        pairs = pairs.merge(df1, left_on='idx1', right_index=True)\n",
    "        pairs = pairs.merge(df2, left_on='idx2', right_index=True, suffixes=['_1','_2'])\n",
    "        pairs['Intersection'] = pairs.apply(lambda x: (x['geometry_1'].intersection(x['geometry_2'])).buffer(0), axis=1)\n",
    "        pairs = gpd.GeoDataFrame(pairs, columns=pairs.columns, crs=df1.crs)\n",
    "        cols = pairs.columns.tolist()\n",
    "        cols.remove('geometry_1')\n",
    "        cols.remove('geometry_2')\n",
    "        cols.remove('sidx')\n",
    "        cols.remove('bbox')\n",
    "        cols.remove('Intersection')\n",
    "        dfinter = pairs[cols+['Intersection']].copy()\n",
    "        dfinter.rename(columns={'Intersection':'geometry'}, inplace=True)\n",
    "        dfinter = gpd.GeoDataFrame(dfinter, columns=dfinter.columns, crs=pairs.crs)\n",
    "        dfinter = dfinter.loc[dfinter.geometry.is_empty==False]\n",
    "        dfinter.drop(['idx1','idx2'], inplace=True, axis=1)\n",
    "        return dfinter\n",
    "    elif how=='difference':\n",
    "        spatial_index = df2.sindex\n",
    "        df1['bbox'] = df1.geometry.apply(lambda x: x.bounds)\n",
    "        df1['sidx']=df1.bbox.apply(lambda x:list(spatial_index.intersection(x)))\n",
    "        df1['new_g'] = df1.apply(lambda x: reduce(lambda x, y: x.difference(y).buffer(0), \n",
    "                                 [x.geometry]+list(df2.iloc[x.sidx].geometry)) , axis=1)\n",
    "        df1.geometry = df1.new_g\n",
    "        df1 = df1.loc[df1.geometry.is_empty==False].copy()\n",
    "        df1.drop(['bbox', 'sidx', 'new_g'], axis=1, inplace=True)\n",
    "        return df1\n",
    "    elif how=='symmetric_difference':\n",
    "        df1['idx1'] = df1.index.tolist()\n",
    "        df2['idx2'] = df2.index.tolist()\n",
    "        df1['idx2'] = np.nan\n",
    "        df2['idx1'] = np.nan\n",
    "        dfsym = df1.merge(df2, on=['idx1','idx2'], how='outer', suffixes=['_1','_2'])\n",
    "        dfsym['geometry'] = dfsym.geometry_1\n",
    "        dfsym.loc[dfsym.geometry_2.isnull()==False, 'geometry'] = dfsym.loc[dfsym.geometry_2.isnull()==False, 'geometry_2']\n",
    "        dfsym.drop(['geometry_1', 'geometry_2'], axis=1, inplace=True)\n",
    "        dfsym = gpd.GeoDataFrame(dfsym, columns=dfsym.columns, crs=df1.crs)\n",
    "        spatial_index = dfsym.sindex\n",
    "        dfsym['bbox'] = dfsym.geometry.apply(lambda x: x.bounds)\n",
    "        dfsym['sidx'] = dfsym.bbox.apply(lambda x:list(spatial_index.intersection(x)))\n",
    "        dfsym['idx'] = dfsym.index.values\n",
    "        dfsym.apply(lambda x: x.sidx.remove(x.idx), axis=1)\n",
    "        dfsym['new_g'] = dfsym.apply(lambda x: reduce(lambda x, y: x.difference(y).buffer(0), \n",
    "                         [x.geometry]+list(dfsym.iloc[x.sidx].geometry)) , axis=1)\n",
    "        dfsym.geometry = dfsym.new_g\n",
    "        dfsym = dfsym.loc[dfsym.geometry.is_empty==False].copy()\n",
    "        dfsym.drop(['bbox', 'sidx', 'idx', 'idx1','idx2', 'new_g'], axis=1, inplace=True)\n",
    "        return dfsym\n",
    "    elif how=='union':\n",
    "        dfinter = spatial_overlays(df1, df2, how='intersection')\n",
    "        dfsym = spatial_overlays(df1, df2, how='symmetric_difference')\n",
    "        dfunion = dfinter.append(dfsym)\n",
    "        dfunion.reset_index(inplace=True, drop=True)\n",
    "        return dfunion\n",
    "    elif how=='identity':\n",
    "        dfunion = spatial_overlays(df1, df2, how='union')\n",
    "        cols1 = df1.columns.tolist()\n",
    "        cols2 = df2.columns.tolist()\n",
    "        cols1.remove('geometry')\n",
    "        cols2.remove('geometry')\n",
    "        cols2 = set(cols2).intersection(set(cols1))\n",
    "        cols1 = list(set(cols1).difference(set(cols2)))\n",
    "        cols2 = [col+'_1' for col in cols2]\n",
    "        dfunion = dfunion[(dfunion[cols1+cols2].isnull()==False).values]\n",
    "        return dfunion\n",
    "\n",
    "def intersect(name_of_source_file,\n",
    "              name_of_ERA_file,\n",
    "              name_of_result_file,\n",
    "              field_ID,\n",
    "              dic_rename):\n",
    "    \"\"\"\n",
    "    @ author:                  Shervan Gharari\n",
    "    @ Github:                  https://github.com/ShervanGharari/shapefile_standardization\n",
    "    @ author's email id:       sh.gharari@gmail.com\n",
    "    @license:                  MIT\n",
    "\n",
    "    This function gets name of a shapefile, its directory, and its extensions (such as gpkg or shp) and\n",
    "    save a stadard shapefile. if presence it also save the holes of a shapefile\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    name_of_source_file: string, the name of the source file including path and extension\n",
    "    name_of_ERA_file: string, the name of the final file including path and extension\n",
    "    name_of_result_file: string, the name of the file that includes holes including path\n",
    "        and extension\n",
    "    field_ID: string, the name of the field in the original shapefile that is used for keeping\n",
    "        track of holes\n",
    "    dic_rename: float; the tolerance to compare area before and after correction and report\n",
    "        differences\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "\n",
    "    Saves Files\n",
    "    -------\n",
    "    a shp file that includes corrected polygones\n",
    "    a possible shapefile that includes the removed problematice holes\n",
    "    a log file in the same folder descringin the invalid shapefiles\n",
    "    \"\"\"\n",
    "    \n",
    "    shp1 = gpd.read_file (name_of_source_file)\n",
    "    shp1.crs = 'epsg:4326'\n",
    "    shp1[\"lon_c\"] = shp1.centroid.x # pass calculated centroid lon to the shp1\n",
    "    shp1[\"lat_c\"] = shp1.centroid.y # pass calculated centroid lat to the shp1\n",
    "    shp2 = gpd.read_file (name_of_ERA_file)\n",
    "    shp_int = intersection_shp(shp1, shp2)\n",
    "    shp_int = shp_int.rename(columns=dic_rename) # weight of each ERA5 grid in subbasin\n",
    "    shp_int = shp_int.sort_values(by=[field_ID])\n",
    "    shp_int.to_file(name_of_result_file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hillslope correction\n",
    "### # there is no 49 hillslope and there is only one shape in hillslope 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-9b5468c6d22b>:51: UserWarning: `keep_geom_type=True` in overlay resulted in 1936 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  shp_temp = gpd.overlay(shp, shp, how='intersection')\n",
      "<ipython-input-2-9b5468c6d22b>:58: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: EPSG:4326\n",
      "Right CRS: None\n",
      "\n",
      "  shp_temp = gpd.overlay(shp_temp, cat, how='difference')\n",
      "<ipython-input-2-9b5468c6d22b>:63: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shp_temp = shp_temp.buffer(-epsilon, cap_style=2, join_style=2)\n"
     ]
    }
   ],
   "source": [
    "# the 2 digit pfaf code for the shapefile to be processed\n",
    "# list of IDs for downloading the processing\n",
    "IDs = ['11', '12', '13', '14', '15', '16', '17', '18',\n",
    "       '21', '22', '23', '24', '25', '26', '27', '28', '29',\n",
    "       '31', '32', '33', '34', '35',\n",
    "       '41', '42', '43', '44', '45', '46', '47', '48',\n",
    "       '51', '52', '53', '54', '55', '56', '57',\n",
    "       '61', '62', '63', '64', '65', '66', '67',\n",
    "       '71', '72', '73', '74', '75', '76', '77', '78',\n",
    "       '81', '82', '83', '84', '85', '86',\n",
    "       '91']\n",
    "# in this folder create subfolders cat, riv, hill, cat_step_1,cat_step_2\n",
    "path = '/Users/shg096/Desktop/MERIT_Hydro/'\n",
    "# break the hillslopes into separaete hillslopes between the river segments\n",
    "for ID in IDs:\n",
    "    shp_hill (path+'hill/hillslope_'+ID+'_clean.shp',\n",
    "              path+'cat/cat_pfaf_'+ID+'_MERIT_Hydro_v07_Basins_v01_bugfix1.shp',\n",
    "              path+'hill_step_0/hillslope_'+ID+'_clean_corr1_test.shp',\n",
    "              0.0000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding the COMID to the decomposed unresolved hillslopes\n",
    "## the COMIDs are inclluding both mainland and islands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = ['11', '12', '13', '14', '15', '16', '17', '18',\n",
    "       '21', '22', '23', '24', '25', '26', '27', '28', '29',\n",
    "       '31', '32', '33', '34', '35', '36',\n",
    "       '41', '42', '43', '44', '45', '46', '47', '48',\n",
    "       '51', '52', '53', '54', '55', '56', '57',\n",
    "       '61', '62', '63', '64', '65', '66', '67',\n",
    "       '71', '72', '73', '74', '75', '76', '77', '78',\n",
    "       '81', '82', '83', '84', '85', '86',\n",
    "       '91'] # copy past hillslope 36 to the folder with name _corr1\n",
    "\n",
    "# add COMID ID to modified hillslope\n",
    "for ID in IDs:\n",
    "    shp = gpd.read_file(path+'hill_step_0/hillslope_'+ID+'_clean_corr1_test.shp')\n",
    "    cat = gpd.read_file(path+'cat/cat_pfaf_'+ID+'_MERIT_Hydro_v07_Basins_v01_bugfix1.shp')\n",
    "    shp ['COMID'] = np.arange(shp.shape[0])+max(cat.COMID)+1\n",
    "    shp.to_file(path+'hill_fixed/hillslope_'+ID+'_clean_fixed_test.shp')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# assign WGS84 projection to the fixed shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define projection for the corrected hillslopes\n",
    "for ID in IDs:\n",
    "    shp = gpd.read_file(path+'hill_fixed/hillslope_'+ID+'_clean_fixed_test.shp')\n",
    "    shp.crs = {'init': 'epsg:4326', 'no_defs': True}\n",
    "    shp.to_file(path+'hill_fixed/hillslope_'+ID+'_clean_fixed_test.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up the colomn names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define projection for the corrected hillslopes\n",
    "for ID in IDs:\n",
    "    shp = gpd.read_file(path+'hill_fixed/hillslope_'+ID+'_clean_fixed_test.shp')\n",
    "    shp = shp.drop(columns=['FID'])\n",
    "    shp.to_file(path+'hill_fixed/hillslope_'+ID+'_clean_fixed_test.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculating the area only for north america"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = ['71', '72', '73', '74', '75', '76', '77', '78',\n",
    "       '81', '82', '83', '84', '85', '86'] # of north america\n",
    "\n",
    "# define projection for the corrected hillslopes\n",
    "for ID in IDs:\n",
    "    shp = gpd.read_file(path+'hill_fixed/hillslope_'+ID+'_clean_fixed.shp')\n",
    "    shp_temp = shp.to_crs(\"EPSG:6933\") # projection for north america\n",
    "    shp_temp['unitarea'] = shp_temp.area\n",
    "    shp['unitarea'] = shp_temp['unitarea']/1000000 # meter2 to km2\n",
    "    shp.to_file(path+'hill_fixed/hillslope_'+ID+'_clean_fixed_area.shp')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
